{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If you run this notebook at colab.research.google.com, you need to install packages with the following command*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade gcsfs intake intake-xarray zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access to data in the cloud (GCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gcsfs\n",
    "import xarray as xr\n",
    "import intake\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from Google Cloud Storage (gcsfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access and listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cloud file system access point:\n",
    "fs = gcsfs.GCSFileSystem(project='alert-ground-261008', token='anon', access='read_only')\n",
    "\n",
    "# And list content of a bucket:\n",
    "fs.ls('opendata_bdo2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But data access with ``gcsfs`` is critically dependant on the GCS set-up. For instance the following project does not allow to list the bucket content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs2 = gcsfs.GCSFileSystem(project='alert-ground-261008', token='anon', access='read_only')\n",
    "try:\n",
    "    fs2.ls('data_bdo2020')\n",
    "except:\n",
    "    print(sys.exc_info()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, some dataset may not be free and use a requester pay model. \n",
    "In this case, you would have to properly manage authentication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs3 = gcsfs.GCSFileSystem(project='poised-honor-358', token='anon')\n",
    "try:\n",
    "    fs3.ls('sonific01')\n",
    "except ValueError as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcsmap = fs.get_mapper(\"opendata_bdo2020/EN.4.2.1.f.analysis.g10.zarr\")\n",
    "ds = xr.open_zarr(gcsmap)\n",
    "\n",
    "# ds = xr.open_dataset(\"gcs://opendata_bdo2020/EN.4.2.1.f.analysis.g10.zarr\",\n",
    "#                      backend_kwargs={\"storage_options\": {\"project\": \"alert-ground-261008\", \"token\": 'anon', 'access':'read_only'}},\n",
    "#                     engine=\"zarr\")\n",
    "\n",
    "print(\"Size of the dataset:\", ds.nbytes/1e9,\"Gb\")\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load another dataset:\n",
    "gcsmap = fs.get_mapper('opendata_bdo2020/GLOBAL_ARGO_SDL2000')\n",
    "ds = xr.open_zarr(gcsmap, consolidated=False)\n",
    "print(\"Size of the dataset:\", ds.nbytes/1e9,\"Gb\")\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use intake catalog of data\n",
    "\n",
    "The catalog also uses the gcsfs entry point, but with intake it's transparent to the user:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access and listing of the catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intake import open_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_url = 'https://raw.githubusercontent.com/obidam/ds2-2022/main/ds2_data_catalog.yml'\n",
    "cat = open_catalog(catalog_url)\n",
    "list(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = cat['en4'].read_chunked()\n",
    "print(\"Size of the dataset:\", ds.nbytes/1e9,\"Gb\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds  = cat[\"sea_surface_height\"].to_dask()\n",
    "print(\"Size of the dataset:\", ds.nbytes/1e9,\"Gb\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pangeo data\n",
    "\n",
    "https://github.com/pangeo-data/pangeo-datastore\n",
    "\n",
    "https://catalog.pangeo.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intake import open_catalog\n",
    "\n",
    "pangeo_cat = open_catalog(\"https://raw.githubusercontent.com/pangeo-data/pangeo-datastore/master/intake-catalogs/master.yaml\")\n",
    "list(pangeo_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(pangeo_cat.ocean)\n",
    "# print(list(pangeo_cat.atmosphere))\n",
    "# print(list(pangeo_cat.hydro))\n",
    "# pangeo_cat.walk(depth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMIP6 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this only needs to be created once\n",
    "gcs = gcsfs.GCSFileSystem(token='anon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv('https://storage.googleapis.com/cmip6/cmip6-zarr-consolidated-stores.csv')\n",
    "df_full.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_full.query(\"activity_id=='CMIP' & table_id == 'Omon' & variable_id == 'thetao' & experiment_id == 'historical' & member_id == 'r1i1p1f1'\")\n",
    "df = df_full.query(\"activity_id=='CMIP' & table_id == 'Omon' & institution_id == 'CNRM-CERFACS' & experiment_id == 'historical'\")\n",
    "# df = df_full.query('institution_id == \"CNRM-CERFACS\" & member_id==\"r1i1p1f2\" & source_id==\"CNRM-CM6-1\"')\n",
    "\n",
    "# df = df_full.query(\"activity_id=='CMIP' & table_id == 'Omon' & variable_id == 'thetao' & experiment_id == 'abrupt-4xCO2'\")\n",
    "\n",
    "# df = df.query(\"source_id=='CNRM-CM6-1-HR' & variable_id=='thetao'\") # Horizontal resolution up to 1/4 deg\n",
    "# df = df.query(\"source_id=='CNRM-ESM2-1' & variable_id=='thetao'\") # Horizontal resolution up to 1deg\n",
    "df = df.query(\"source_id=='CNRM-ESM2-1' & (variable_id=='thetao' | variable_id=='so')\") # Horizontal resolution up to 1deg\n",
    "\n",
    "# df = df.sort_values('version')\n",
    "df = df.sort_values('member_id')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the path to a specific zarr store (the first one from the dataframe above)\n",
    "zstore = df.zstore.values[-1]\n",
    "print(zstore)\n",
    "\n",
    "# create a mutable-mapping-style interface to the store\n",
    "mapper = gcs.get_mapper(zstore)\n",
    "\n",
    "# open it using xarray and zarr\n",
    "ds = xr.open_zarr(mapper, consolidated=True)\n",
    "print(\"Size of the dataset:\", ds.nbytes/1e9,\"Gb\")\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst = ds['thetao'].sel(lev=0, method='nearest')\n",
    "sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_cmip6(df_row):\n",
    "    # get the path to zarr store\n",
    "    zstore = df.zstore.values[-1]\n",
    "#     print(zstore)\n",
    "    \n",
    "    # create a mutable-mapping-style interface to the store\n",
    "    mapper = gcs.get_mapper(zstore)\n",
    "\n",
    "    # open it using xarray and zarr\n",
    "    return xr.open_zarr(mapper, consolidated=True)\n",
    "\n",
    "ds = open_cmip6(df.iloc[0])\n",
    "print(\"Size of the dataset:\", ds.nbytes/1e9,\"Gb\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute size of the df selection:\n",
    "total_size = 0 # Gb\n",
    "for index, row in df.iterrows():\n",
    "    ds = open_cmip6(row)\n",
    "    total_size += ds.nbytes/1e9\n",
    "print(\"Size of the selection of datasets:\", total_size, \"Gb\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds2",
   "language": "python",
   "name": "ds2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
